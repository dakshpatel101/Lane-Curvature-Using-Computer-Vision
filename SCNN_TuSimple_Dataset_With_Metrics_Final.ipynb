{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fb0415f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import required packages\n",
    "import json\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "import json\n",
    "import os\n",
    "\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.cluster import DBSCAN\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import torch.optim as optim\n",
    "from torch.nn.modules.loss import _Loss\n",
    "from torch.autograd import Variable\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c8b4917a",
   "metadata": {},
   "outputs": [],
   "source": [
    "json_gt = [json.loads(line) for line in open('/Users/dakshpatel/Desktop/Computer_Vision/Project/Code/TuSimple_Dataset/test_label_new.json')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e8c3c7ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "from IPython.display import FileLink, display\n",
    "\n",
    "def download_file(path, download_file_name):\n",
    "    os.chdir('/Users/dakshpatel/Desktop/Computer_Vision/Project/Code/TuSimple_Dataset')\n",
    "    zip_name = f\"/Users/dakshpatel/Desktop/Computer_Vision/Project/Code/TuSimple_Dataset/{download_file_name}.zip\"\n",
    "    command = f\"zip {zip_name} {path} -r\"\n",
    "    result = subprocess.run(command, shell=True, capture_output=True, text=True)\n",
    "    if result.returncode != 0:\n",
    "        print(\"Unable to run zip command!\")\n",
    "        print(result.stderr)\n",
    "        return\n",
    "    display(FileLink(f'{download_file_name}.zip'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e3918c2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_path(path):\n",
    "    \"\"\"split path tree into list\"\"\"\n",
    "    folders = []\n",
    "    while True:\n",
    "        path, folder = os.path.split(path)\n",
    "        if folder != \"\":\n",
    "            folders.insert(0, folder)\n",
    "        else:\n",
    "            if path != \"\":\n",
    "                folders.insert(0, path)\n",
    "            break\n",
    "    return folders\n",
    "\n",
    "def getLane_tusimple(prob_map, y_px_gap, pts, thresh, resize_shape=None):\n",
    "    \"\"\"\n",
    "    Arguments:\n",
    "    ----------\n",
    "    prob_map: prob map for single lane, np array size (h, w)\n",
    "    resize_shape:  reshape size target, (H, W)\n",
    "\n",
    "    Return:\n",
    "    ----------\n",
    "    coords: x coords bottom up every y_px_gap px, 0 for non-exist, in resized shape\n",
    "    \"\"\"\n",
    "    if resize_shape is None:\n",
    "        resize_shape = prob_map.shape\n",
    "    h, w = prob_map.shape\n",
    "    H, W = resize_shape\n",
    "\n",
    "    coords = np.zeros(pts)\n",
    "    for i in range(pts):\n",
    "        y = int((H - 10 - i * y_px_gap) * h / H)\n",
    "        if y < 0:\n",
    "            break\n",
    "        line = prob_map[y, :]\n",
    "        id = np.argmax(line)\n",
    "        if line[id] > thresh:\n",
    "            coords[i] = int(id / w * W)\n",
    "    if (coords > 0).sum() < 2:\n",
    "        coords = np.zeros(pts)\n",
    "    return coords\n",
    "\n",
    "def prob2lines_tusimple(seg_pred, exist, resize_shape=None, smooth=True, y_px_gap=10, pts=None, thresh=0.3):\n",
    "    \"\"\"\n",
    "    Arguments:\n",
    "    ----------\n",
    "    seg_pred:      np.array size (5, h, w)\n",
    "    resize_shape:  reshape size target, (H, W)\n",
    "    exist:       list of existence, e.g. [0, 1, 1, 0]\n",
    "    smooth:      whether to smooth the probability or not\n",
    "    y_px_gap:    y pixel gap for sampling\n",
    "    pts:     how many points for one lane\n",
    "    thresh:  probability threshold\n",
    "\n",
    "    Return:\n",
    "    ----------\n",
    "    coordinates: [x, y] list of lanes, e.g.: [ [[9, 569], [50, 549]] ,[[630, 569], [647, 549]] ]\n",
    "    \"\"\"\n",
    "    if resize_shape is None:\n",
    "        resize_shape = seg_pred.shape[1:]  # seg_pred (5, h, w)\n",
    "    _, h, w = seg_pred.shape\n",
    "    H, W = resize_shape\n",
    "    coordinates = []\n",
    "\n",
    "    if pts is None:\n",
    "        pts = round(H / 2 / y_px_gap)\n",
    "\n",
    "    seg_pred = np.ascontiguousarray(np.transpose(seg_pred, (1, 2, 0)))\n",
    "    for i in range(6):\n",
    "        prob_map = seg_pred[..., i + 1]\n",
    "        if smooth:\n",
    "            prob_map = cv2.blur(prob_map, (9, 9), borderType=cv2.BORDER_REPLICATE)\n",
    "        if exist[i] > 0:\n",
    "            coords = getLane_tusimple(prob_map, y_px_gap, pts, thresh, resize_shape)\n",
    "            coordinates.append(\n",
    "                [[coords[j], H - 10 - j * y_px_gap] if coords[j] > 0 else [-1, H - 10 - j * y_px_gap] for j in\n",
    "                 range(pts)])\n",
    "\n",
    "    return coordinates\n",
    "\n",
    "# Define the LaneEval class with updated metrics\n",
    "class LaneEval(object):\n",
    "    lr = LinearRegression()\n",
    "    pixel_thresh = 20\n",
    "    pt_thresh = 0.85\n",
    "\n",
    "    @staticmethod\n",
    "    def get_angle(xs, y_samples):\n",
    "        xs, ys = xs[xs >= 0], y_samples[xs >= 0]\n",
    "        if len(xs) > 1:\n",
    "            LaneEval.lr.fit(ys[:, None], xs)\n",
    "            k = LaneEval.lr.coef_[0]\n",
    "            theta = np.arctan(k)\n",
    "        else:\n",
    "            theta = 0\n",
    "        return theta\n",
    "\n",
    "    @staticmethod\n",
    "    def line_accuracy(pred, gt, thresh):\n",
    "        pred = np.array([p if p >= 0 else -100 for p in pred])\n",
    "        gt = np.array([g if g >= 0 else -100 for g in gt])\n",
    "        return np.sum(np.where(np.abs(pred - gt) < thresh, 1., 0.)) / len(gt)\n",
    "\n",
    "    @staticmethod\n",
    "    def bench(pred, gt, y_samples, running_time):\n",
    "        if any(len(p) != len(y_samples) for p in pred):\n",
    "            raise Exception('Format of lanes error.')\n",
    "        if running_time > 200 or len(gt) + 2 < len(pred):\n",
    "            return 0., 0., 1.\n",
    "        angles = [LaneEval.get_angle(np.array(x_gts), np.array(y_samples)) for x_gts in gt]\n",
    "        threshs = [LaneEval.pixel_thresh / np.cos(angle) for angle in angles]\n",
    "        line_accs = []\n",
    "        fp, fn = 0., 0.\n",
    "        matched = 0.\n",
    "        for x_gts, thresh in zip(gt, threshs):\n",
    "            accs = [LaneEval.line_accuracy(np.array(x_preds), np.array(x_gts), thresh) for x_preds in pred]\n",
    "            max_acc = np.max(accs) if len(accs) > 0 else 0.\n",
    "            if max_acc < LaneEval.pt_thresh:\n",
    "                fn += 1\n",
    "            else:\n",
    "                matched += 1\n",
    "            line_accs.append(max_acc)\n",
    "        fp = len(pred) - matched\n",
    "        if len(gt) > 4 and fn > 0:\n",
    "            fn -= 1\n",
    "        s = sum(line_accs)\n",
    "        if len(gt) > 4:\n",
    "            s -= min(line_accs)\n",
    "        accuracy = s / max(min(4.0, len(gt)), 1.)\n",
    "        return accuracy, fp / len(pred) if len(pred) > 0 else 0., fn / max(min(len(gt), 4.) , 1.)\n",
    "\n",
    "    @staticmethod\n",
    "    def bench_one_submit(pred_file, gt_file):\n",
    "        try:\n",
    "            json_pred = [json.loads(line) for line in open(pred_file).readlines()]\n",
    "        except BaseException as e:\n",
    "            raise Exception('Fail to load json file of the prediction.')\n",
    "        json_gt = [json.loads(line) for line in open(gt_file).readlines()]\n",
    "        if len(json_gt) != len(json_pred):\n",
    "            raise Exception('We do not get the predictions of all the test tasks')\n",
    "        gts = {l['raw_file']: l for l in json_gt}\n",
    "        accuracy, fp, fn = 0., 0., 0.\n",
    "        tp, tn = 0, 0\n",
    "        for pred in json_pred:\n",
    "            if 'raw_file' not in pred or 'lanes' not in pred or 'run_time' not in pred:\n",
    "                raise Exception('raw_file or lanes or run_time not in some predictions.')\n",
    "            raw_file = pred['raw_file']\n",
    "            pred_lanes = pred['lanes']\n",
    "            run_time = pred['run_time']\n",
    "            if raw_file not in gts:\n",
    "                raise Exception('Some raw_file from your predictions do not exist in the test tasks.')\n",
    "            gt = gts[raw_file]\n",
    "            gt_lanes = gt['lanes']\n",
    "            y_samples = gt['h_samples']\n",
    "            try:\n",
    "                a, p, n = LaneEval.bench(pred_lanes, gt_lanes, y_samples, run_time)\n",
    "            except BaseException as e:\n",
    "                raise Exception('Format of lanes error.')\n",
    "            accuracy += a\n",
    "            fp += p\n",
    "            fn += n\n",
    "\n",
    "            tp += sum((pred_lanes == gt_lanes) & (gt_lanes == 1))\n",
    "            tn += sum((pred_lanes == gt_lanes) & (gt_lanes == 0))\n",
    "            \n",
    "        num = len(gts)\n",
    "        accuracy /= num\n",
    "        fp /= num\n",
    "        fn /= num\n",
    "\n",
    "        fpr = fp / (fp + tn)\n",
    "        fnr = fn / (fn + tp)\n",
    "\n",
    "        # the first return parameter is the default ranking parameter\n",
    "        return json.dumps([\n",
    "            {'name': 'Accuracy', 'value': accuracy, 'order': 'desc'},\n",
    "            {'name': 'FP', 'value': fp, 'order': 'asc'},\n",
    "            {'name': 'FN', 'value': fn, 'order': 'asc'},\n",
    "            {'name': 'FPR', 'value': fpr, 'order': 'asc'},\n",
    "            {'name': 'FNR', 'value': fnr, 'order': 'asc'}\n",
    "        ])\n",
    "    \n",
    "    \n",
    "def bench_one(pred_file, gt_file):\n",
    "    try:\n",
    "        json_pred = [json.loads(line) for line in open(pred_file).readlines()]\n",
    "    except BaseException as e:\n",
    "        raise Exception('Fail to load json file of the prediction.')\n",
    "    json_gt = [json.loads(line) for line in open(gt_file).readlines()]\n",
    "    if len(json_gt) != len(json_pred):\n",
    "        raise Exception('We do not get the predictions of all the test tasks')\n",
    "    gts = {l['raw_file']: l for l in json_gt}\n",
    "    accuracy, fp, fn = 0., 0., 0.\n",
    "    accuracy_list = []\n",
    "    for pred in json_pred:\n",
    "        if 'raw_file' not in pred or 'lanes' not in pred or 'run_time' not in pred:\n",
    "            raise Exception('raw_file or lanes or run_time not in some predictions.')\n",
    "        raw_file = pred['raw_file']\n",
    "        pred_lanes = pred['lanes']\n",
    "        run_time = pred['run_time']\n",
    "        if raw_file not in gts:\n",
    "            raise Exception('Some raw_file from your predictions do not exist in the test tasks.')\n",
    "        gt = gts[raw_file]\n",
    "        gt_lanes = gt['lanes']\n",
    "        y_samples = gt['h_samples']\n",
    "        try:\n",
    "            a, p, n = LaneEval.bench(pred_lanes, gt_lanes, y_samples, run_time)\n",
    "            accuracy_list.append((a, raw_file))\n",
    "        except BaseException as e:\n",
    "                raise Exception('Format of lanes error.')\n",
    "    return accuracy_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "30ff6140",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_one_hot(tensor, nClasses):\n",
    "    n, h, w = tensor.size()\n",
    "    one_hot = torch.zeros(n, nClasses, h, w).to(tensor.device).scatter_(1, tensor.view(n, 1, h, w), 1)\n",
    "    return one_hot\n",
    "\n",
    "\n",
    "class mIoULoss(nn.Module):\n",
    "    def __init__(self, weight=None, size_average=True, n_classes=6):\n",
    "        super(mIoULoss, self).__init__()\n",
    "        self.classes = n_classes\n",
    "\n",
    "    def forward(self, inputs, target_oneHot):\n",
    "        \"\"\"\n",
    "        IoU Loss for individual examples\n",
    "        inputs - N x {Classes or higher} x H x W\n",
    "        target_oneHot - N x {Classes or higher} x H x W\n",
    "        BG can be ignored\n",
    "        \"\"\"\n",
    "\n",
    "        N = inputs.size()[0]\n",
    "        C = inputs.size()[1]\n",
    "\n",
    "        # predicted probabilities for each pixel along channel\n",
    "        inputs = F.softmax(inputs, dim=1)\n",
    "\n",
    "        # Numerator Product\n",
    "        inter = inputs * target_oneHot\n",
    "        # Sum over all pixels N x C x H x W => N x C\n",
    "        inter = inter.view(N, C, -1).sum(2)\n",
    "\n",
    "        # Denominator\n",
    "        union = inputs + target_oneHot - (inputs * target_oneHot)\n",
    "        # Sum over all pixels N x C x H x W => N x C\n",
    "        union = union.view(N, C, -1).sum(2)\n",
    "\n",
    "        loss = inter / union\n",
    "\n",
    "        ## Return average loss over classes and batch\n",
    "        return -(loss[:, -self.classes].mean() - 1.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "65e9635e",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = '/Users/dakshpatel/Desktop/Computer_Vision/Project/Code/TuSimple_Dataset/TUSimple'\n",
    "\n",
    "class LaneDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, dataset_path= PATH, train=True, size=(800, 288)):\n",
    "        self._dataset_path = dataset_path\n",
    "        self._mode = \"train\" if train else \"test\"\n",
    "        self._image_size = size # w, h\n",
    "        self._data = []\n",
    "\n",
    "        if self._mode == \"train\":\n",
    "            file_path = \"train_val_gt.txt\"\n",
    "        elif self._mode == \"test\":\n",
    "            file_path = \"test_gt.txt\"\n",
    "        self._process_list(os.path.join(self._dataset_path, \"train_set/seg_label/list\", file_path))\n",
    "            \n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self._dataset_path + (\"/train_set\" if self._mode == \"train\" else \"/test_set\") + self._data[idx][0]\n",
    "        image = cv2.imread(img_path)\n",
    "        h, w, c = image.shape\n",
    "        image = cv2.resize(image, self._image_size, interpolation=cv2.INTER_LINEAR)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        ins_segmentation_path = self._dataset_path + \"/train_set\" + self._data[idx][1]\n",
    "        ins_segmentation_image = cv2.imread(ins_segmentation_path)\n",
    "        ins_segmentation_image = ins_segmentation_image[:, :, 0]\n",
    "        ins_segmentation_image = cv2.resize(ins_segmentation_image, self._image_size, interpolation=cv2.INTER_LINEAR)\n",
    "        \n",
    "        segmentation_image = ins_segmentation_image.copy()\n",
    "        segmentation_image[segmentation_image > 0] = 1\n",
    "        \n",
    "        image = torch.from_numpy(image).float().permute((2, 0, 1))\n",
    "        segmentation_image = torch.from_numpy(segmentation_image.copy()).to(torch.int64)\n",
    "        ins_segmentation_image =  torch.from_numpy(ins_segmentation_image.copy())\n",
    "        \n",
    "        exists = [int(i) for i in self._data[idx][2]]\n",
    "        exists = torch.as_tensor(exists)\n",
    "        \n",
    "        output = {\n",
    "            'img_path' : img_path,\n",
    "            'img' : image,\n",
    "            'segLabel' : segmentation_image,\n",
    "            'IsegLabel' : ins_segmentation_image,\n",
    "            'exist' : exists\n",
    "        }\n",
    "        \n",
    "        return output\n",
    "    \n",
    "    def _process_list(self, file_path):\n",
    "        with open(file_path) as f:\n",
    "            for line in f:\n",
    "                words = line.split()\n",
    "                image = words[0]\n",
    "                segmentation = words[1]\n",
    "                exists = words[2:]\n",
    "                self._data.append((image, segmentation, exists))        \n",
    "                \n",
    "    def __len__(self):\n",
    "        return len(self._data)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c3732927",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enet pytorch code retrieved from https://github.com/davidtvs/PyTorch-ENet/blob/master/models/enet.py\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.parameter import Parameter\n",
    "\n",
    "\n",
    "class InitialBlock(nn.Module):\n",
    "    \"\"\"The initial block is composed of two branches:\n",
    "    1. a main branch which performs a regular convolution with stride 2;\n",
    "    2. an extension branch which performs max-pooling.\n",
    "    Doing both operations in parallel and concatenating their results\n",
    "    allows for efficient downsampling and expansion. The main branch\n",
    "    outputs 13 feature maps while the extension branch outputs 3, for a\n",
    "    total of 16 feature maps after concatenation.\n",
    "    Keyword arguments:\n",
    "    - in_channels (int): the number of input channels.\n",
    "    - out_channels (int): the number output channels.\n",
    "    - kernel_size (int, optional): the kernel size of the filters used in\n",
    "    the convolution layer. Default: 3.\n",
    "    - padding (int, optional): zero-padding added to both sides of the\n",
    "    input. Default: 0.\n",
    "    - bias (bool, optional): Adds a learnable bias to the output if\n",
    "    ``True``. Default: False.\n",
    "    - relu (bool, optional): When ``True`` ReLU is used as the activation\n",
    "    function; otherwise, PReLU is used. Default: True.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 in_channels,\n",
    "                 out_channels,\n",
    "                 bias=False,\n",
    "                 relu=True):\n",
    "        super().__init__()\n",
    "\n",
    "        if relu:\n",
    "            activation = nn.ReLU\n",
    "        else:\n",
    "            activation = nn.PReLU\n",
    "\n",
    "        # Main branch - As stated above the number of output channels for this\n",
    "        # branch is the total minus 3, since the remaining channels come from\n",
    "        # the extension branch\n",
    "        self.main_branch = nn.Conv2d(\n",
    "            in_channels,\n",
    "            out_channels - 3,\n",
    "            kernel_size=3,\n",
    "            stride=2,\n",
    "            padding=1,\n",
    "            bias=bias)\n",
    "\n",
    "        # Extension branch\n",
    "        self.ext_branch = nn.MaxPool2d(3, stride=2, padding=1)\n",
    "\n",
    "        # Initialize batch normalization to be used after concatenation\n",
    "        self.batch_norm = nn.BatchNorm2d(out_channels)\n",
    "\n",
    "        # PReLU layer to apply after concatenating the branches\n",
    "        self.out_activation = activation()\n",
    "\n",
    "    def forward(self, x):\n",
    "        main = self.main_branch(x)\n",
    "        ext = self.ext_branch(x)\n",
    "\n",
    "        # Concatenate branches\n",
    "        out = torch.cat((main, ext), 1)\n",
    "\n",
    "        # Apply batch normalization\n",
    "        out = self.batch_norm(out)\n",
    "\n",
    "        return self.out_activation(out)\n",
    "\n",
    "\n",
    "class RegularBottleneck(nn.Module):\n",
    "    \"\"\"Regular bottlenecks are the main building block of ENet.\n",
    "    Main branch:\n",
    "    1. Shortcut connection.\n",
    "    Extension branch:\n",
    "    1. 1x1 convolution which decreases the number of channels by\n",
    "    ``internal_ratio``, also called a projection;\n",
    "    2. regular, dilated or asymmetric convolution;\n",
    "    3. 1x1 convolution which increases the number of channels back to\n",
    "    ``channels``, also called an expansion;\n",
    "    4. dropout as a regularizer.\n",
    "    Keyword arguments:\n",
    "    - channels (int): the number of input and output channels.\n",
    "    - internal_ratio (int, optional): a scale factor applied to\n",
    "    ``channels`` used to compute the number of\n",
    "    channels after the projection. eg. given ``channels`` equal to 128 and\n",
    "    internal_ratio equal to 2 the number of channels after the projection\n",
    "    is 64. Default: 4.\n",
    "    - kernel_size (int, optional): the kernel size of the filters used in\n",
    "    the convolution layer described above in item 2 of the extension\n",
    "    branch. Default: 3.\n",
    "    - padding (int, optional): zero-padding added to both sides of the\n",
    "    input. Default: 0.\n",
    "    - dilation (int, optional): spacing between kernel elements for the\n",
    "    convolution described in item 2 of the extension branch. Default: 1.\n",
    "    asymmetric (bool, optional): flags if the convolution described in\n",
    "    item 2 of the extension branch is asymmetric or not. Default: False.\n",
    "    - dropout_prob (float, optional): probability of an element to be\n",
    "    zeroed. Default: 0 (no dropout).\n",
    "    - bias (bool, optional): Adds a learnable bias to the output if\n",
    "    ``True``. Default: False.\n",
    "    - relu (bool, optional): When ``True`` ReLU is used as the activation\n",
    "    function; otherwise, PReLU is used. Default: True.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 channels,\n",
    "                 internal_ratio=4,\n",
    "                 kernel_size=3,\n",
    "                 padding=0,\n",
    "                 dilation=1,\n",
    "                 asymmetric=False,\n",
    "                 dropout_prob=0,\n",
    "                 bias=False,\n",
    "                 relu=True):\n",
    "        super().__init__()\n",
    "\n",
    "        # Check in the internal_scale parameter is within the expected range\n",
    "        # [1, channels]\n",
    "        if internal_ratio <= 1 or internal_ratio > channels:\n",
    "            raise RuntimeError(\"Value out of range. Expected value in the \"\n",
    "                               \"interval [1, {0}], got internal_scale={1}.\"\n",
    "                               .format(channels, internal_ratio))\n",
    "\n",
    "        internal_channels = channels // internal_ratio\n",
    "\n",
    "        if relu:\n",
    "            activation = nn.ReLU\n",
    "        else:\n",
    "            activation = nn.PReLU\n",
    "\n",
    "        # Main branch - shortcut connection\n",
    "\n",
    "        # Extension branch - 1x1 convolution, followed by a regular, dilated or\n",
    "        # asymmetric convolution, followed by another 1x1 convolution, and,\n",
    "        # finally, a regularizer (spatial dropout). Number of channels is constant.\n",
    "\n",
    "        # 1x1 projection convolution\n",
    "        self.ext_conv1 = nn.Sequential(\n",
    "            nn.Conv2d(\n",
    "                channels,\n",
    "                internal_channels,\n",
    "                kernel_size=1,\n",
    "                stride=1,\n",
    "                bias=bias), nn.BatchNorm2d(internal_channels), activation())\n",
    "\n",
    "        # If the convolution is asymmetric we split the main convolution in\n",
    "        # two. Eg. for a 5x5 asymmetric convolution we have two convolution:\n",
    "        # the first is 5x1 and the second is 1x5.\n",
    "        if asymmetric:\n",
    "            self.ext_conv2 = nn.Sequential(\n",
    "                nn.Conv2d(\n",
    "                    internal_channels,\n",
    "                    internal_channels,\n",
    "                    kernel_size=(kernel_size, 1),\n",
    "                    stride=1,\n",
    "                    padding=(padding, 0),\n",
    "                    dilation=dilation,\n",
    "                    bias=bias), nn.BatchNorm2d(internal_channels), activation(),\n",
    "                nn.Conv2d(\n",
    "                    internal_channels,\n",
    "                    internal_channels,\n",
    "                    kernel_size=(1, kernel_size),\n",
    "                    stride=1,\n",
    "                    padding=(0, padding),\n",
    "                    dilation=dilation,\n",
    "                    bias=bias), nn.BatchNorm2d(internal_channels), activation())\n",
    "        else:\n",
    "            self.ext_conv2 = nn.Sequential(\n",
    "                nn.Conv2d(\n",
    "                    internal_channels,\n",
    "                    internal_channels,\n",
    "                    kernel_size=kernel_size,\n",
    "                    stride=1,\n",
    "                    padding=padding,\n",
    "                    dilation=dilation,\n",
    "                    bias=bias), nn.BatchNorm2d(internal_channels), activation())\n",
    "\n",
    "        # 1x1 expansion convolution\n",
    "        self.ext_conv3 = nn.Sequential(\n",
    "            nn.Conv2d(\n",
    "                internal_channels,\n",
    "                channels,\n",
    "                kernel_size=1,\n",
    "                stride=1,\n",
    "                bias=bias), nn.BatchNorm2d(channels), activation())\n",
    "\n",
    "        self.ext_regul = nn.Dropout2d(p=dropout_prob)\n",
    "\n",
    "        # PReLU layer to apply after adding the branches\n",
    "        self.out_activation = activation()\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Main branch shortcut\n",
    "        main = x\n",
    "\n",
    "        # Extension branch\n",
    "        ext = self.ext_conv1(x)\n",
    "        ext = self.ext_conv2(ext)\n",
    "        ext = self.ext_conv3(ext)\n",
    "        ext = self.ext_regul(ext)\n",
    "\n",
    "        # Add main and extension branches\n",
    "        out = main + ext\n",
    "\n",
    "        return self.out_activation(out)\n",
    "\n",
    "\n",
    "class DownsamplingBottleneck(nn.Module):\n",
    "    \"\"\"Downsampling bottlenecks further downsample the feature map size.\n",
    "    Main branch:\n",
    "    1. max pooling with stride 2; indices are saved to be used for\n",
    "    unpooling later.\n",
    "    Extension branch:\n",
    "    1. 2x2 convolution with stride 2 that decreases the number of channels\n",
    "    by ``internal_ratio``, also called a projection;\n",
    "    2. regular convolution (by default, 3x3);\n",
    "    3. 1x1 convolution which increases the number of channels to\n",
    "    ``out_channels``, also called an expansion;\n",
    "    4. dropout as a regularizer.\n",
    "    Keyword arguments:\n",
    "    - in_channels (int): the number of input channels.\n",
    "    - out_channels (int): the number of output channels.\n",
    "    - internal_ratio (int, optional): a scale factor applied to ``channels``\n",
    "    used to compute the number of channels after the projection. eg. given\n",
    "    ``channels`` equal to 128 and internal_ratio equal to 2 the number of\n",
    "    channels after the projection is 64. Default: 4.\n",
    "    - return_indices (bool, optional):  if ``True``, will return the max\n",
    "    indices along with the outputs. Useful when unpooling later.\n",
    "    - dropout_prob (float, optional): probability of an element to be\n",
    "    zeroed. Default: 0 (no dropout).\n",
    "    - bias (bool, optional): Adds a learnable bias to the output if\n",
    "    ``True``. Default: False.\n",
    "    - relu (bool, optional): When ``True`` ReLU is used as the activation\n",
    "    function; otherwise, PReLU is used. Default: True.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 in_channels,\n",
    "                 out_channels,\n",
    "                 internal_ratio=4,\n",
    "                 return_indices=False,\n",
    "                 dropout_prob=0,\n",
    "                 bias=False,\n",
    "                 relu=True):\n",
    "        super().__init__()\n",
    "\n",
    "        # Store parameters that are needed later\n",
    "        self.return_indices = return_indices\n",
    "\n",
    "        # Check in the internal_scale parameter is within the expected range\n",
    "        # [1, channels]\n",
    "        if internal_ratio <= 1 or internal_ratio > in_channels:\n",
    "            raise RuntimeError(\"Value out of range. Expected value in the \"\n",
    "                               \"interval [1, {0}], got internal_scale={1}. \"\n",
    "                               .format(in_channels, internal_ratio))\n",
    "\n",
    "        internal_channels = in_channels // internal_ratio\n",
    "\n",
    "        if relu:\n",
    "            activation = nn.ReLU\n",
    "        else:\n",
    "            activation = nn.PReLU\n",
    "\n",
    "        # Main branch - max pooling followed by feature map (channels) padding\n",
    "        self.main_max1 = nn.MaxPool2d(\n",
    "            2,\n",
    "            stride=2,\n",
    "            return_indices=return_indices)\n",
    "\n",
    "        # Extension branch - 2x2 convolution, followed by a regular, dilated or\n",
    "        # asymmetric convolution, followed by another 1x1 convolution. Number\n",
    "        # of channels is doubled.\n",
    "\n",
    "        # 2x2 projection convolution with stride 2\n",
    "        self.ext_conv1 = nn.Sequential(\n",
    "            nn.Conv2d(\n",
    "                in_channels,\n",
    "                internal_channels,\n",
    "                kernel_size=2,\n",
    "                stride=2,\n",
    "                bias=bias), nn.BatchNorm2d(internal_channels), activation())\n",
    "\n",
    "        # Convolution\n",
    "        self.ext_conv2 = nn.Sequential(\n",
    "            nn.Conv2d(\n",
    "                internal_channels,\n",
    "                internal_channels,\n",
    "                kernel_size=3,\n",
    "                stride=1,\n",
    "                padding=1,\n",
    "                bias=bias), nn.BatchNorm2d(internal_channels), activation())\n",
    "\n",
    "        # 1x1 expansion convolution\n",
    "        self.ext_conv3 = nn.Sequential(\n",
    "            nn.Conv2d(\n",
    "                internal_channels,\n",
    "                out_channels,\n",
    "                kernel_size=1,\n",
    "                stride=1,\n",
    "                bias=bias), nn.BatchNorm2d(out_channels), activation())\n",
    "\n",
    "        self.ext_regul = nn.Dropout2d(p=dropout_prob)\n",
    "\n",
    "        # PReLU layer to apply after concatenating the branches\n",
    "        self.out_activation = activation()\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Main branch shortcut\n",
    "        if self.return_indices:\n",
    "            main, max_indices = self.main_max1(x)\n",
    "        else:\n",
    "            main = self.main_max1(x)\n",
    "\n",
    "        # Extension branch\n",
    "        ext = self.ext_conv1(x)\n",
    "        ext = self.ext_conv2(ext)\n",
    "        ext = self.ext_conv3(ext)\n",
    "        ext = self.ext_regul(ext)\n",
    "\n",
    "        # Main branch channel padding\n",
    "        n, ch_ext, h, w = ext.size()\n",
    "        ch_main = main.size()[1]\n",
    "        padding = torch.zeros(n, ch_ext - ch_main, h, w)\n",
    "\n",
    "        # Before concatenating, check if main is on the CPU or GPU and\n",
    "        # convert padding accordingly\n",
    "        if main.is_cuda:\n",
    "            padding = padding.cuda()\n",
    "\n",
    "        # Concatenate\n",
    "        main = torch.cat((main, padding), 1)\n",
    "\n",
    "        # Add main and extension branches\n",
    "        out = main + ext\n",
    "\n",
    "        return self.out_activation(out), max_indices\n",
    "\n",
    "\n",
    "class UpsamplingBottleneck(nn.Module):\n",
    "    \"\"\"The upsampling bottlenecks upsample the feature map resolution using max\n",
    "    pooling indices stored from the corresponding downsampling bottleneck.\n",
    "    Main branch:\n",
    "    1. 1x1 convolution with stride 1 that decreases the number of channels by\n",
    "    ``internal_ratio``, also called a projection;\n",
    "    2. max unpool layer using the max pool indices from the corresponding\n",
    "    downsampling max pool layer.\n",
    "    Extension branch:\n",
    "    1. 1x1 convolution with stride 1 that decreases the number of channels by\n",
    "    ``internal_ratio``, also called a projection;\n",
    "    2. transposed convolution (by default, 3x3);\n",
    "    3. 1x1 convolution which increases the number of channels to\n",
    "    ``out_channels``, also called an expansion;\n",
    "    4. dropout as a regularizer.\n",
    "    Keyword arguments:\n",
    "    - in_channels (int): the number of input channels.\n",
    "    - out_channels (int): the number of output channels.\n",
    "    - internal_ratio (int, optional): a scale factor applied to ``in_channels``\n",
    "     used to compute the number of channels after the projection. eg. given\n",
    "     ``in_channels`` equal to 128 and ``internal_ratio`` equal to 2 the number\n",
    "     of channels after the projection is 64. Default: 4.\n",
    "    - dropout_prob (float, optional): probability of an element to be zeroed.\n",
    "    Default: 0 (no dropout).\n",
    "    - bias (bool, optional): Adds a learnable bias to the output if ``True``.\n",
    "    Default: False.\n",
    "    - relu (bool, optional): When ``True`` ReLU is used as the activation\n",
    "    function; otherwise, PReLU is used. Default: True.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 in_channels,\n",
    "                 out_channels,\n",
    "                 internal_ratio=4,\n",
    "                 dropout_prob=0,\n",
    "                 bias=False,\n",
    "                 relu=True):\n",
    "        super().__init__()\n",
    "\n",
    "        # Check in the internal_scale parameter is within the expected range\n",
    "        # [1, channels]\n",
    "        if internal_ratio <= 1 or internal_ratio > in_channels:\n",
    "            raise RuntimeError(\"Value out of range. Expected value in the \"\n",
    "                               \"interval [1, {0}], got internal_scale={1}. \"\n",
    "                               .format(in_channels, internal_ratio))\n",
    "\n",
    "        internal_channels = in_channels // internal_ratio\n",
    "\n",
    "        if relu:\n",
    "            activation = nn.ReLU\n",
    "        else:\n",
    "            activation = nn.PReLU\n",
    "\n",
    "        # Main branch - max pooling followed by feature map (channels) padding\n",
    "        self.main_conv1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size=1, bias=bias),\n",
    "            nn.BatchNorm2d(out_channels))\n",
    "\n",
    "        # Remember that the stride is the same as the kernel_size, just like\n",
    "        # the max pooling layers\n",
    "        self.main_unpool1 = nn.MaxUnpool2d(kernel_size=2)\n",
    "\n",
    "        # Extension branch - 1x1 convolution, followed by a regular, dilated or\n",
    "        # asymmetric convolution, followed by another 1x1 convolution. Number\n",
    "        # of channels is doubled.\n",
    "\n",
    "        # 1x1 projection convolution with stride 1\n",
    "        self.ext_conv1 = nn.Sequential(\n",
    "            nn.Conv2d(\n",
    "                in_channels, internal_channels, kernel_size=1, bias=bias),\n",
    "            nn.BatchNorm2d(internal_channels), activation())\n",
    "\n",
    "        # Transposed convolution\n",
    "        self.ext_tconv1 = nn.ConvTranspose2d(\n",
    "            internal_channels,\n",
    "            internal_channels,\n",
    "            kernel_size=2,\n",
    "            stride=2,\n",
    "            bias=bias)\n",
    "        self.ext_tconv1_bnorm = nn.BatchNorm2d(internal_channels)\n",
    "        self.ext_tconv1_activation = activation()\n",
    "\n",
    "        # 1x1 expansion convolution\n",
    "        self.ext_conv2 = nn.Sequential(\n",
    "            nn.Conv2d(\n",
    "                internal_channels, out_channels, kernel_size=1, bias=bias),\n",
    "            nn.BatchNorm2d(out_channels), activation())\n",
    "\n",
    "        self.ext_regul = nn.Dropout2d(p=dropout_prob)\n",
    "\n",
    "        # PReLU layer to apply after concatenating the branches\n",
    "        self.out_activation = activation()\n",
    "\n",
    "    def forward(self, x, max_indices, output_size):\n",
    "        # Main branch shortcut\n",
    "        main = self.main_conv1(x)\n",
    "        main = self.main_unpool1(\n",
    "            main, max_indices, output_size=output_size)\n",
    "\n",
    "        # Extension branch\n",
    "        ext = self.ext_conv1(x)\n",
    "        ext = self.ext_tconv1(ext, output_size=output_size)\n",
    "        ext = self.ext_tconv1_bnorm(ext)\n",
    "        ext = self.ext_tconv1_activation(ext)\n",
    "        ext = self.ext_conv2(ext)\n",
    "        ext = self.ext_regul(ext)\n",
    "\n",
    "        # Add main and extension branches\n",
    "        out = main + ext\n",
    "\n",
    "        return self.out_activation(out)\n",
    "\n",
    "\n",
    "class SpatialSoftmax(nn.Module):\n",
    "    def __init__(self, temperature=1, device='cpu'):\n",
    "        super(SpatialSoftmax, self).__init__()\n",
    "\n",
    "        if temperature:\n",
    "            self.temperature = Parameter(torch.ones(1) * temperature).to(device)\n",
    "        else:\n",
    "            self.temperature = 1.\n",
    "\n",
    "    def forward(self, feature):\n",
    "        feature = feature.view(feature.shape[0], -1, feature.shape[1] * feature.shape[2])\n",
    "        softmax_attention = F.softmax(feature / self.temperature, dim=-1)\n",
    "\n",
    "        return softmax_attention\n",
    "\n",
    "\n",
    "class ENet_SAD(nn.Module):\n",
    "    \"\"\"Generate the ENet model.\n",
    "    Keyword arguments:\n",
    "    - num_classes (int): the number of classes to segment.\n",
    "    - encoder_relu (bool, optional): When ``True`` ReLU is used as the\n",
    "    activation function in the encoder blocks/layers; otherwise, PReLU\n",
    "    is used. Default: False.\n",
    "    - decoder_relu (bool, optional): When ``True`` ReLU is used as the\n",
    "    activation function in the decoder blocks/layers; otherwise, PReLU\n",
    "    is used. Default: True.\n",
    "    - sad (bool, optional): When ``True``, SAD is added to model\n",
    "    . If False, SAD is removed.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, input_size, sad=False, encoder_relu=False, decoder_relu=True, weight_share=True, dataset='TUSimple'):\n",
    "        super().__init__()\n",
    "\n",
    "        # Init parameter\n",
    "        input_w, input_h = input_size\n",
    "        self.fc_input_feature = 7 * int(input_w / 16) * int(input_h / 16)\n",
    "        self.num_classes = 7 if dataset != 'BDD100K' else 1\n",
    "        self.scale_background = 0.4\n",
    "\n",
    "        # Loss scale factor for ENet w/o SAD\n",
    "        self.scale_seg = 1.0\n",
    "        self.scale_exist = 0.1\n",
    "\n",
    "        # Loss scale factor for ENet w SAD\n",
    "        self.scale_sad_seg = 1.0\n",
    "        self.scale_sad_iou = 0.1\n",
    "        self.scale_sad_exist = 0.1\n",
    "        self.scale_sad_distill = 0.1\n",
    "\n",
    "        # Loss function\n",
    "        self.dataset = dataset\n",
    "        if dataset != 'BDD100K':\n",
    "            self.ce_loss = nn.CrossEntropyLoss(weight=torch.tensor([self.scale_background, 1, 1, 1, 1, 1, 1]))\n",
    "            self.bce_loss = nn.BCELoss()\n",
    "            self.iou_loss = mIoULoss(n_classes=6)\n",
    "        else:\n",
    "            self.ce_loss = nn.BCEWithLogitsLoss()\n",
    "            self.bce_loss = nn.BCELoss()\n",
    "            self.iou_loss = mIoULoss(n_classes=1)\n",
    "\n",
    "        # Encoder generator\n",
    "        def get_encoder_block(n=2):\n",
    "            seq = nn.Sequential()\n",
    "            seq.add_module('regular%d_1' % n, RegularBottleneck(128, padding=1, dropout_prob=0.1, relu=encoder_relu))\n",
    "            seq.add_module('dilated%d_2' % n, RegularBottleneck(128, dilation=2, padding=2, dropout_prob=0.1, relu=encoder_relu))\n",
    "            seq.add_module('asymmetric%d_3' % n, RegularBottleneck(128, kernel_size=5, padding=2, asymmetric=True, dropout_prob=0.1, relu=encoder_relu))\n",
    "            seq.add_module('dilated%d_4' % n, RegularBottleneck(128, dilation=4, padding=4, dropout_prob=0.1, relu=encoder_relu))\n",
    "            seq.add_module('regular%d_5' % n, RegularBottleneck(128, padding=1, dropout_prob=0.1, relu=encoder_relu))\n",
    "            seq.add_module('dilated%d_6' % n, RegularBottleneck(128, dilation=8, padding=8, dropout_prob=0.1, relu=encoder_relu))\n",
    "            seq.add_module('asymmetric%d_7' % n, RegularBottleneck(128, kernel_size=5, asymmetric=True, padding=2, dropout_prob=0.1, relu=encoder_relu))\n",
    "            seq.add_module('dilated%d_8' % n, RegularBottleneck(128, dilation=16, padding=16, dropout_prob=0.1, relu=encoder_relu))\n",
    "            return seq\n",
    "\n",
    "        # Stage 0 - Initial block\n",
    "        self.initial_block = InitialBlock(3, 16, relu=encoder_relu)\n",
    "        self.sad = sad\n",
    "\n",
    "        # Stage 1 - Encoder (E1)\n",
    "        self.downsample1 = DownsamplingBottleneck(16, 64, return_indices=True, dropout_prob=0.01, relu=encoder_relu)\n",
    "        self.encoder1 = nn.Sequential()\n",
    "        self.encoder1.add_module('regular1_1', RegularBottleneck(64, padding=1, dropout_prob=0.01, relu=encoder_relu))\n",
    "        self.encoder1.add_module('regular1_2', RegularBottleneck(64, padding=1, dropout_prob=0.01, relu=encoder_relu))\n",
    "        self.encoder1.add_module('regular1_3', RegularBottleneck(64, padding=1, dropout_prob=0.01, relu=encoder_relu))\n",
    "        self.encoder1.add_module('regular1_4', RegularBottleneck(64, padding=1, dropout_prob=0.01, relu=encoder_relu))\n",
    "\n",
    "        # Shared Encoder (E2~E4)\n",
    "        # Stage 2 - Encoder (E2)\n",
    "        self.downsample2 = DownsamplingBottleneck(64, 128, return_indices=True, dropout_prob=0.1, relu=encoder_relu)\n",
    "        self.encoder2 = get_encoder_block(n=2)\n",
    "\n",
    "        # Stage 3 - Encoder (E3)\n",
    "        self.encoder3 = self.encoder2 if weight_share else get_encoder_block(3)\n",
    "\n",
    "        # Stage 4 - Encoder (E4)\n",
    "        self.encoder4 = self.encoder2 if weight_share else get_encoder_block(4)\n",
    "\n",
    "        # Stage 5 - Decoder (D1)\n",
    "        self.upsample4_0 = UpsamplingBottleneck(256, 64, dropout_prob=0.1, relu=decoder_relu)\n",
    "        self.regular4_1 = RegularBottleneck(64, padding=1, dropout_prob=0.1, relu=decoder_relu)\n",
    "        self.regular4_2 = RegularBottleneck(64, padding=1, dropout_prob=0.1, relu=decoder_relu)\n",
    "\n",
    "        # Stage 6 - Decoder (D2)\n",
    "        self.upsample5_0 = UpsamplingBottleneck(64, 16, dropout_prob=0.1, relu=decoder_relu)\n",
    "        self.regular5_1 = RegularBottleneck(16, padding=1, dropout_prob=0.1, relu=decoder_relu)\n",
    "        self.transposed_conv = nn.ConvTranspose2d(16, self.num_classes, kernel_size=3, stride=2, padding=1, bias=False)\n",
    "\n",
    "        # AT_GEN\n",
    "        if self.sad:\n",
    "            self.at_gen_upsample = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=False)\n",
    "            self.at_gen_l2_loss = nn.MSELoss(reduction='mean')\n",
    "\n",
    "        # Lane exist (P1)\n",
    "        self.exist = nn.Sequential(nn.Conv2d(128, self.num_classes, 1),\n",
    "                                   nn.Softmax(dim=1),\n",
    "                                   nn.AvgPool2d(2, 2),)\n",
    "        self.fc = nn.Sequential(nn.Linear(self.fc_input_feature, 128),\n",
    "                                nn.ReLU(),\n",
    "                                nn.Linear(128, 6),\n",
    "                                nn.Sigmoid(),)\n",
    "\n",
    "    def at_gen(self, x1, x2):\n",
    "        \"\"\"\n",
    "        x1 - previous encoder step feature map\n",
    "        x2 - current encoder step feature map\n",
    "        \"\"\"\n",
    "\n",
    "        # G^2_sum\n",
    "        sps = SpatialSoftmax(device=x1.device)\n",
    "\n",
    "        if x1.size() != x2.size():\n",
    "            x1 = x1.pow(2).sum(dim=1)\n",
    "            x1 = sps(x1)\n",
    "            x2 = x2.pow(2).sum(dim=1, keepdim=True)\n",
    "            x2 = torch.squeeze(self.at_gen_upsample(x2), dim=1)\n",
    "            x2 = sps(x2)\n",
    "        else:\n",
    "            x1 = x1.pow(2).sum(dim=1)\n",
    "            x1 = sps(x1)\n",
    "            x2 = x2.pow(2).sum(dim=1)\n",
    "            x2 = sps(x2)\n",
    "\n",
    "        loss = self.at_gen_l2_loss(x1, x2)\n",
    "        return loss\n",
    "\n",
    "    def forward(self, img, seg_gt=None, exist_gt=None, sad_loss=False):\n",
    "        # Stage 0 - Initial block\n",
    "        input_size = img.size()\n",
    "        x_0 = self.initial_block(img)\n",
    "\n",
    "        # AT-GEN after each E2, E3, E4\n",
    "        # Stage 1 - Encoder (E1)\n",
    "        stage1_input_size = x_0.size()\n",
    "        x, max_indices1 = self.downsample1(x_0)\n",
    "        x_1 = self.encoder1(x)\n",
    "\n",
    "        # Stage 2 - Encoder (E2)\n",
    "        stage2_input_size = x_1.size()\n",
    "        x, max_indices2 = self.downsample2(x_1)\n",
    "        x_2 = self.encoder2(x)\n",
    "        if self.sad:\n",
    "            loss_2 = self.at_gen(x_1, x_2)\n",
    "\n",
    "        # Stage 3 - Encoder (E3)\n",
    "        x_3 = self.encoder3(x_2)\n",
    "        if self.sad:\n",
    "            loss_3 = self.at_gen(x_2, x_3)\n",
    "\n",
    "        # Stage 4 - Encoder (E4)\n",
    "        x_4 = self.encoder4(x_3)\n",
    "        if self.sad:\n",
    "            loss_4 = self.at_gen(x_3, x_4)\n",
    "\n",
    "        # Concatenate E3, E4\n",
    "        x_34 = torch.cat((x_3, x_4), dim=1)\n",
    "\n",
    "        # Stage 4 - Decoder (D1)\n",
    "        x = self.upsample4_0(x_34, max_indices2, output_size=stage2_input_size)\n",
    "        x = self.regular4_1(x)\n",
    "        x = self.regular4_2(x)\n",
    "\n",
    "        # Stage 5 - Decoder (D2)\n",
    "        x = self.upsample5_0(x, max_indices1, output_size=stage1_input_size)\n",
    "        x = self.regular5_1(x)\n",
    "        seg_pred = self.transposed_conv(x, output_size=input_size)\n",
    "\n",
    "        # lane exist\n",
    "        y = self.exist(x_4)\n",
    "        y = y.view(-1, self.fc_input_feature)\n",
    "        exist_pred = self.fc(y)\n",
    "\n",
    "        # loss calculation\n",
    "        if seg_gt is not None and exist_gt is not None:\n",
    "            # L = L_seg + a * L_iou + b * L_exist + c * L_distill\n",
    "            if self.sad:\n",
    "                if self.dataset != 'BDD100K':\n",
    "                    loss_seg = self.ce_loss(seg_pred, seg_gt.long())\n",
    "#                     seg_gt_onehot = to_one_hot(seg_gt, 7)\n",
    "                    seg_gt_onehot = F.one_hot(seg_gt.long(), num_classes = 7)\n",
    "                    seg_gt_onehot = seg_gt_onehot.permute(0, 3, 1, 2)\n",
    "                else:\n",
    "                    loss_seg = self.ce_loss(seg_pred.squeeze(dim=1), seg_gt.float())\n",
    "                    seg_gt_onehot = seg_gt.unsqueeze(dim=1)\n",
    "\n",
    "#                 loss_iou = self.iou_loss(seg_pred, seg_gt_onehot)\n",
    "                loss_iou = self.iou_loss(seg_pred, seg_gt_onehot.long())\n",
    "                loss_exist = self.bce_loss(exist_pred, exist_gt.float())\n",
    "                loss = loss_seg * self.scale_sad_seg + loss_iou * self.scale_sad_iou + loss_exist * self.scale_sad_exist\n",
    "\n",
    "                # Add SAD loss after 40K episodes\n",
    "                if sad_loss:\n",
    "                    loss_distill = loss_2 + loss_3 + loss_4\n",
    "                    loss += loss_distill * self.scale_sad_distill\n",
    "\n",
    "            else:\n",
    "                loss_seg = self.ce_loss(seg_pred, seg_gt.long())\n",
    "                loss_exist = self.bce_loss(exist_pred, exist_gt.float())\n",
    "                loss = loss_seg * self.scale_seg + loss_exist * self.scale_exist\n",
    "\n",
    "        else:\n",
    "            loss_seg = torch.tensor(0, dtype=img.dtype, device=img.device)\n",
    "            loss_exist = torch.tensor(0, dtype=img.dtype, device=img.device)\n",
    "            loss = torch.tensor(0, dtype=img.dtype, device=img.device)\n",
    "\n",
    "        return seg_pred, exist_pred, loss_seg, loss_exist, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8b13fd01",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.models as models\n",
    "\n",
    "\n",
    "class SCNN(nn.Module):\n",
    "    def __init__(\n",
    "            self,\n",
    "            input_size,\n",
    "            ms_ks=9,\n",
    "            pretrained=True\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Argument\n",
    "            ms_ks: kernel size in message passing conv\n",
    "        \"\"\"\n",
    "        super(SCNN, self).__init__()\n",
    "        self.pretrained = pretrained\n",
    "        self.net_init(input_size, ms_ks)\n",
    "        if not pretrained:\n",
    "            self.weight_init()\n",
    "\n",
    "        self.scale_background = 0.4\n",
    "        self.scale_seg = 1.0\n",
    "        self.scale_exist = 0.1\n",
    "\n",
    "        self.ce_loss = nn.CrossEntropyLoss(weight=torch.tensor([self.scale_background, 1, 1, 1, 1, 1, 1]))\n",
    "        self.bce_loss = nn.BCELoss()\n",
    "\n",
    "    def forward(self, img, seg_gt=None, exist_gt=None):\n",
    "        x = self.backbone(img)\n",
    "        x = self.layer1(x)\n",
    "        x = self.message_passing_forward(x)\n",
    "        x = self.layer2(x)\n",
    "\n",
    "        seg_pred = F.interpolate(x, scale_factor=8, mode='bilinear', align_corners=True)\n",
    "\n",
    "        x = self.layer3(x)\n",
    "        x = x.view(-1, self.fc_input_feature)\n",
    "        exist_pred = self.fc(x)\n",
    "\n",
    "        if seg_gt is not None and exist_gt is not None:\n",
    "            loss_seg = self.ce_loss(seg_pred, seg_gt.long())\n",
    "            loss_exist = self.bce_loss(exist_pred, exist_gt.float())\n",
    "            loss = loss_seg * self.scale_seg + loss_exist * self.scale_exist\n",
    "        else:\n",
    "            loss_seg = torch.tensor(0, dtype=img.dtype, device=img.device)\n",
    "            loss_exist = torch.tensor(0, dtype=img.dtype, device=img.device)\n",
    "            loss = torch.tensor(0, dtype=img.dtype, device=img.device)\n",
    "\n",
    "        return seg_pred, exist_pred, loss_seg, loss_exist, loss\n",
    "\n",
    "    def message_passing_forward(self, x):\n",
    "        Vertical = [True, True, False, False]\n",
    "        Reverse = [False, True, False, True]\n",
    "        for ms_conv, v, r in zip(self.message_passing, Vertical, Reverse):\n",
    "            x = self.message_passing_once(x, ms_conv, v, r)\n",
    "        return x\n",
    "\n",
    "    def message_passing_once(self, x, conv, vertical=True, reverse=False):\n",
    "        \"\"\"\n",
    "        Argument:\n",
    "        ----------\n",
    "        x: input tensor\n",
    "        vertical: vertical message passing or horizontal\n",
    "        reverse: False for up-down or left-right, True for down-up or right-left\n",
    "        \"\"\"\n",
    "        nB, C, H, W = x.shape\n",
    "        if vertical:\n",
    "            slices = [x[:, :, i:(i + 1), :] for i in range(H)]\n",
    "            dim = 2\n",
    "        else:\n",
    "            slices = [x[:, :, :, i:(i + 1)] for i in range(W)]\n",
    "            dim = 3\n",
    "        if reverse:\n",
    "            slices = slices[::-1]\n",
    "\n",
    "        out = [slices[0]]\n",
    "        for i in range(1, len(slices)):\n",
    "            out.append(slices[i] + F.relu(conv(out[i - 1])))\n",
    "        if reverse:\n",
    "            out = out[::-1]\n",
    "        return torch.cat(out, dim=dim)\n",
    "\n",
    "    def net_init(self, input_size, ms_ks):\n",
    "        input_w, input_h = input_size\n",
    "        self.fc_input_feature = 7 * int(input_w/16) * int(input_h/16)\n",
    "        self.backbone = models.vgg16_bn(pretrained=self.pretrained).features\n",
    "\n",
    "        # ----------------- process backbone -----------------\n",
    "        for i in [34, 37, 40]:\n",
    "            conv = self.backbone._modules[str(i)]\n",
    "            dilated_conv = nn.Conv2d(\n",
    "                conv.in_channels, conv.out_channels, conv.kernel_size, stride=conv.stride,\n",
    "                padding=tuple(p * 2 for p in conv.padding), dilation=2, bias=(conv.bias is not None)\n",
    "            )\n",
    "            dilated_conv.load_state_dict(conv.state_dict())\n",
    "            self.backbone._modules[str(i)] = dilated_conv\n",
    "        self.backbone._modules.pop('33')\n",
    "        self.backbone._modules.pop('43')\n",
    "\n",
    "        # ----------------- SCNN part -----------------\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv2d(512, 1024, 3, padding=4, dilation=4, bias=False),\n",
    "            nn.BatchNorm2d(1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(1024, 128, 1, bias=False),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU()  # (nB, 128, 36, 100)\n",
    "        )\n",
    "\n",
    "        # ----------------- add message passing -----------------\n",
    "        self.message_passing = nn.ModuleList()\n",
    "        self.message_passing.add_module('up_down', nn.Conv2d(128, 128, (1, ms_ks), padding=(0, ms_ks // 2), bias=False))\n",
    "        self.message_passing.add_module('down_up', nn.Conv2d(128, 128, (1, ms_ks), padding=(0, ms_ks // 2), bias=False))\n",
    "        self.message_passing.add_module('left_right',\n",
    "                                        nn.Conv2d(128, 128, (ms_ks, 1), padding=(ms_ks // 2, 0), bias=False))\n",
    "        self.message_passing.add_module('right_left',\n",
    "                                        nn.Conv2d(128, 128, (ms_ks, 1), padding=(ms_ks // 2, 0), bias=False))\n",
    "        # (nB, 128, 36, 100)\n",
    "\n",
    "        # ----------------- SCNN part -----------------\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Dropout2d(0.1),\n",
    "            nn.Conv2d(128, 7, 1)  # get (nB, 5, 36, 100)\n",
    "        )\n",
    "\n",
    "        self.layer3 = nn.Sequential(\n",
    "            nn.Softmax(dim=1),  # (nB, 5, 36, 100)\n",
    "            nn.AvgPool2d(2, 2),  # (nB, 5, 18, 50)\n",
    "        )\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(self.fc_input_feature, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 6),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def weight_init(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                m.reset_parameters()\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                m.weight.data[:] = 1.\n",
    "                m.bias.data.zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9c8995dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = LaneDataset(size=(800, 288))\n",
    "\n",
    "train_size = int(0.85 * len(dataset))\n",
    "val_size = len(dataset) - train_size\n",
    "train_ds, val_ds = torch.utils.data.random_split(dataset, [train_size, val_size], generator=torch.Generator().manual_seed(42))\n",
    "\n",
    "train_dataloader = torch.utils.data.DataLoader(train_ds, batch_size=16, shuffle=False)\n",
    "val_dataloader = torch.utils.data.DataLoader(val_ds, batch_size=16, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2ec921c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<torch.utils.data.dataloader.DataLoader object at 0x16b34fb10>\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x168c48ed0>\n"
     ]
    }
   ],
   "source": [
    "print(train_dataloader)\n",
    "print(val_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "329b20ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 7, 288, 800])\n",
      "torch.Size([8, 6])\n",
      "torch.Size([8, 7, 288, 800])\n",
      "torch.Size([8, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dakshpatel/anaconda3/lib/python3.11/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/Users/dakshpatel/anaconda3/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_BN_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_BN_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 7, 288, 800])\n",
      "torch.Size([8, 6])\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "tensor = torch.ones((8, 3, 288, 800)).to(device)\n",
    "seg_gt = torch.zeros((8, 288, 800)).long().to(device)\n",
    "exist_gt = torch.ones((8, 6)).to(device)\n",
    "\n",
    "enet_sad = ENet_SAD((800, 288), sad=True, dataset='TUSImple')\n",
    "enet_sad.to(device)\n",
    "enet_sad.train(mode=True)\n",
    "print(enet_sad(tensor, seg_gt, exist_gt, sad_loss=True)[0].shape)\n",
    "print(enet_sad(tensor, seg_gt, exist_gt, sad_loss=True)[1].shape)\n",
    "\n",
    "enet = ENet_SAD((800, 288), sad=False, dataset='TUSImple')\n",
    "enet.to(device)\n",
    "enet.train(mode=True)\n",
    "print(enet(tensor, seg_gt, exist_gt, sad_loss=True)[0].shape)\n",
    "print(enet(tensor, seg_gt, exist_gt, sad_loss=True)[1].shape)\n",
    "\n",
    "scnn = SCNN((800, 288), pretrained=True)\n",
    "scnn.to(device)\n",
    "scnn.train(mode=True)\n",
    "result = scnn(tensor, seg_gt, exist_gt)\n",
    "print(result[0].shape)\n",
    "print(result[1].shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ab05a70a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim.lr_scheduler import _LRScheduler\n",
    "\n",
    "\n",
    "class PolyLR(_LRScheduler):\n",
    "    def __init__(self, optimizer, pow, max_iter, min_lrs=1e-20, last_epoch=-1, warmup=0):\n",
    "        \"\"\"\n",
    "        :param warmup: how many steps for linearly warmup lr\n",
    "        \"\"\"\n",
    "        self.pow = pow\n",
    "        self.max_iter = max_iter\n",
    "        if not isinstance(min_lrs, list) and not isinstance(min_lrs, tuple):\n",
    "            self.min_lrs = [min_lrs] * len(optimizer.param_groups)\n",
    "\n",
    "        assert isinstance(warmup, int), \"The type of warmup is incorrect, got {}\".format(type(warmup))\n",
    "        self.warmup = max(warmup, 0)\n",
    "\n",
    "        super(PolyLR, self).__init__(optimizer, last_epoch)\n",
    "\n",
    "    def get_lr(self):\n",
    "        if self.last_epoch < self.warmup:\n",
    "            return [base_lr / self.warmup * (self.last_epoch+1) for base_lr in self.base_lrs]\n",
    "\n",
    "        if self.last_epoch < self.max_iter:\n",
    "            coeff = (1 - (self.last_epoch-self.warmup) / (self.max_iter-self.warmup)) ** self.pow\n",
    "        else:\n",
    "            coeff = 0\n",
    "        return [(base_lr - min_lr) * coeff + min_lr\n",
    "                for base_lr, min_lr in zip(self.base_lrs, self.min_lrs)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b7afb4e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def val(net, epoch, model_name, device, optimizer, lr_scheduler, best_val_loss):\n",
    "\n",
    "    print(\"Val Epoch: {}\".format(epoch))\n",
    "\n",
    "    net.eval()\n",
    "    val_loss = 0\n",
    "    val_loss_seg = 0\n",
    "    val_loss_exist = 0\n",
    "    progressbar = tqdm(range(len(val_dataloader)))\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, sample in enumerate(val_dataloader):\n",
    "            img = sample['img'].to(device)\n",
    "            segLabel = sample['IsegLabel'].to(device)\n",
    "            exist = sample['exist'].to(device)\n",
    "\n",
    "            seg_pred, exist_pred, loss_seg, loss_exist, loss = net(img, segLabel, exist)\n",
    "\n",
    "            val_loss += loss.item()\n",
    "            val_loss_seg += loss_seg.item()\n",
    "            val_loss_exist += loss_exist.item()\n",
    "\n",
    "            progressbar.set_description(\"batch loss: {:.3f}\".format(loss.item()))\n",
    "            progressbar.update(1)\n",
    "\n",
    "    progressbar.close()\n",
    "    iter_idx = (epoch + 1) * len(train_dataloader)  # keep align with training process iter_idx\n",
    "\n",
    "    print(\"------------------------\\n\")\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        \n",
    "#         if os.path.exists(prev_save_name):\n",
    "#             os.remove(prev_save_name)\n",
    "        \n",
    "        save_dict = {\n",
    "            \"epoch\": epoch,\n",
    "            \"net\": net.state_dict(),\n",
    "            \"optim\": optimizer.state_dict(),\n",
    "            \"lr_scheduler\": lr_scheduler.state_dict(),\n",
    "            \"best_val_loss\": best_val_loss\n",
    "        }\n",
    "        \n",
    "        torch.save(save_dict, model_name + '.pth')\n",
    "        print(\"model is saved: {}.pth\".format(model_name))\n",
    "        \n",
    "    return best_val_loss\n",
    "\n",
    "#     print(\"------------------------\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a0c3d7ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(model_name):\n",
    "    n_epochs = 12\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    \n",
    "    if model_name == 'enet_sad':\n",
    "        net = ENet_SAD((800, 288), sad=True, dataset='TUSImple')\n",
    "    elif model_name == 'enet':\n",
    "        net = ENet_SAD((800, 288), sad=False, dataset='TUSImple')\n",
    "    elif model_name == 'scnn':\n",
    "        net = SCNN((800, 288), pretrained=True)\n",
    "        \n",
    "    net.to(device)\n",
    "    net.train(mode=True)\n",
    "        \n",
    "    optimizer = optim.SGD(net.parameters(), lr= 1e-2, momentum= 0.9,weight_decay= 2e-5,nesterov= True)\n",
    "    lr_scheduler = PolyLR(optimizer, 0.9, warmup= 50, max_iter= 60000)\n",
    "    \n",
    "    best_val_loss = 1e6\n",
    "        \n",
    "    for epoch in range(0, n_epochs):\n",
    "        print(\"Train Epoch: {}\".format(epoch))\n",
    "        net.train()\n",
    "        train_loss = 0\n",
    "        train_loss_seg = 0\n",
    "        train_loss_exist = 0\n",
    "        progressbar = tqdm(range(len(train_dataloader)))\n",
    "\n",
    "        for batch_idx, sample in enumerate(train_dataloader):\n",
    "            img = sample['img'].to(device)\n",
    "            segLabel = sample['IsegLabel'].to(device)\n",
    "            exist = sample['exist'].to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            if model_name == \"scnn\":\n",
    "                seg_pred, exist_pred, loss_seg, loss_exist, loss = net(img, segLabel, exist)\n",
    "            elif model_name == \"enet\":\n",
    "                seg_pred, exist_pred, loss_seg, loss_exist, loss = net(img, segLabel, exist, False)\n",
    "            elif model_name == \"enet_sad\":\n",
    "                if epoch < 20:\n",
    "                    seg_pred, exist_pred, loss_seg, loss_exist, loss = net(img, segLabel, exist, False)\n",
    "                else:\n",
    "#                     print(\"sad activated\")\n",
    "                    seg_pred, exist_pred, loss_seg, loss_exist, loss = net(img, segLabel, exist, True)\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            lr_scheduler.step()\n",
    "\n",
    "            iter_idx = epoch * len(train_dataloader) + batch_idx\n",
    "            train_loss = loss.item()\n",
    "            train_loss_seg = loss_seg.item()\n",
    "            train_loss_exist = loss_exist.item()\n",
    "            progressbar.set_description(\"batch loss: {:.3f}\".format(loss.item()))\n",
    "            progressbar.update(1)\n",
    "\n",
    "            lr = optimizer.param_groups[0]['lr']\n",
    "\n",
    "        progressbar.close()\n",
    "        \n",
    "        if epoch % 1 == 0:\n",
    "            best_val_loss = val(net, epoch, model_name, device, optimizer, lr_scheduler, best_val_loss)\n",
    "\n",
    "    download_file('/Users/dakshpatel/Desktop/Computer_Vision/Project/Code/TuSimple_Dataset', model_name + '.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9246e63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "batch loss: 0.160: 100%|████████████████████| 193/193 [2:10:31<00:00, 40.58s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Epoch: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "batch loss: 0.184: 100%|████████████████████████| 34/34 [05:29<00:00,  9.70s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------\n",
      "\n",
      "model is saved: scnn.pth\n",
      "Train Epoch: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "batch loss: 0.132: 100%|████████████████████| 193/193 [1:57:44<00:00, 36.60s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Epoch: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "batch loss: 0.160: 100%|████████████████████████| 34/34 [05:35<00:00,  9.85s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------\n",
      "\n",
      "model is saved: scnn.pth\n",
      "Train Epoch: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "batch loss: 0.124: 100%|████████████████████| 193/193 [2:01:14<00:00, 37.69s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Epoch: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "batch loss: 0.154: 100%|████████████████████████| 34/34 [05:30<00:00,  9.72s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------\n",
      "\n",
      "model is saved: scnn.pth\n",
      "Train Epoch: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "batch loss: 0.118: 100%|███████████████████| 193/193 [5:52:40<00:00, 109.64s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Epoch: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "batch loss: 0.150: 100%|████████████████████████| 34/34 [05:18<00:00,  9.36s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------\n",
      "\n",
      "model is saved: scnn.pth\n",
      "Train Epoch: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "batch loss: 0.112: 100%|████████████████████| 193/193 [3:03:44<00:00, 57.12s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Epoch: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "batch loss: 0.149: 100%|████████████████████████| 34/34 [05:20<00:00,  9.44s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------\n",
      "\n",
      "model is saved: scnn.pth\n",
      "Train Epoch: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "batch loss: 0.109: 100%|████████████████████| 193/193 [1:59:47<00:00, 37.24s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Epoch: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "batch loss: 0.148: 100%|████████████████████████| 34/34 [05:22<00:00,  9.49s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------\n",
      "\n",
      "model is saved: scnn.pth\n",
      "Train Epoch: 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "batch loss: 0.105: 100%|████████████████████| 193/193 [2:02:48<00:00, 38.18s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Epoch: 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "batch loss: 0.152: 100%|████████████████████████| 34/34 [05:22<00:00,  9.49s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------\n",
      "\n",
      "Train Epoch: 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "batch loss: 0.102: 100%|████████████████████| 193/193 [3:23:23<00:00, 63.23s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Epoch: 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "batch loss: 0.151: 100%|████████████████████████| 34/34 [05:37<00:00,  9.92s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------\n",
      "\n",
      "Train Epoch: 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "batch loss: 0.097: 100%|████████████████████| 193/193 [2:05:47<00:00, 39.11s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Epoch: 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "batch loss: 0.158: 100%|████████████████████████| 34/34 [05:53<00:00, 10.40s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------\n",
      "\n",
      "Train Epoch: 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "batch loss: 0.094: 100%|████████████████████| 193/193 [2:04:49<00:00, 38.80s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Epoch: 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "batch loss: 0.158: 100%|████████████████████████| 34/34 [05:33<00:00,  9.80s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------\n",
      "\n",
      "Train Epoch: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "batch loss: 0.090: 100%|████████████████████| 193/193 [2:35:22<00:00, 48.30s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Epoch: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "batch loss: 0.164: 100%|████████████████████████| 34/34 [05:31<00:00,  9.75s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------\n",
      "\n",
      "Train Epoch: 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "batch loss: 0.088: 100%|████████████████████| 193/193 [2:44:28<00:00, 51.13s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Epoch: 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "batch loss: 0.172: 100%|████████████████████████| 34/34 [06:34<00:00, 11.61s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "main('scnn')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
